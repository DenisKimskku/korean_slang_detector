================================================================================
XAI ANALYSIS - FILES CREATED
================================================================================

ğŸ“ Main Files:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. xai_analysis.py                    [MAIN SCRIPT]
   â†’ Core XAI analysis implementation
   â†’ Performs SHAP and saliency analysis
   â†’ Compares naive vs trained models
   â†’ Compares label 0 (non-slang) vs label 1 (slang)
   â†’ Generates visualizations and statistics

2. run_xai_analysis.sh                [LAUNCHER]
   â†’ Executable bash script to run analysis
   â†’ Automatically activates conda environment
   â†’ Shows progress and completion messages
   â†’ Usage: ./run_xai_analysis.sh

3. requirements_xai.txt               [DEPENDENCIES]
   â†’ All required Python packages
   â†’ Already installed in forensic conda environment
   â†’ Installation: pip install -r requirements_xai.txt

ğŸ“š Documentation:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

4. QUICKSTART_XAI.md                  [QUICK START GUIDE]
   â†’ Step-by-step instructions to run
   â†’ 3 different ways to execute
   â†’ Expected runtime and output
   â†’ Customization options
   â†’ Troubleshooting tips
   â†’ ** START HERE **

5. XAI_README.md                      [DETAILED DOCUMENTATION]
   â†’ Comprehensive explanation of methods
   â†’ Output structure and organization
   â†’ How to interpret results
   â†’ Configuration options
   â†’ Performance tuning
   â†’ Citation information

6. XAI_FILES_SUMMARY.txt              [THIS FILE]
   â†’ Summary of all created files
   â†’ Quick reference guide

================================================================================
INSTALLATION STATUS
================================================================================

âœ… All dependencies installed in conda environment: forensic
âœ… CUDA available for GPU acceleration
âœ… Test data verified: /home/minseok/forensic/test_gpt.json
âœ… Model checkpoints detected:
   - bert_base
   - distillbert_base
   - electra_base
   - roberta_base
   - roberta_large

================================================================================
ANALYSIS FEATURES
================================================================================

ğŸ” XAI Methods:
   â€¢ SHAP (Shapley Additive Explanations)
     - Shows feature importance per token
     - Quantifies contribution to classification
     - Computed on 100 sample utterances

   â€¢ Saliency Maps (Gradient-based)
     - Visualizes model attention
     - Gradient norm of embeddings
     - Computed on all utterances
     - Normalized to 0-10 scale

ğŸ“Š Comparisons:
   â€¢ Naive vs Trained
     - Base pretrained model vs fine-tuned
     - Shows impact of training
     - 2x2 grid plots per model

   â€¢ Label 0 vs Label 1
     - Non-slang vs slang utterances
     - KDE distribution plots
     - Statistical comparisons

ğŸ¨ Visualizations:
   â€¢ KDE Distribution Plots
     - Smooth probability density curves
     - Compare saliency/SHAP distributions
     - Separate plots for each model type

   â€¢ HTML Interactive Visualizations
     - Token-level saliency heatmaps
     - Red intensity indicates importance
     - Per-conversation analysis
     - Color-coded by label

   â€¢ Comparison Plots
     - Side-by-side naive vs trained
     - 4 subplots per model:
       * Saliency (Non-slang)
       * Saliency (Slang)
       * SHAP (Non-slang)
       * SHAP (Slang)

   â€¢ Summary Plots
     - All models overview
     - Histogram comparisons
     - Cross-model analysis

ğŸ“ˆ Statistics:
   â€¢ Per model, per type (naive/trained):
     - Sample counts (label 0, label 1)
     - Mean saliency values
     - Standard deviation
     - Mean SHAP values
     - Saved to JSON for further analysis

================================================================================
OUTPUT STRUCTURE
================================================================================

xai_results/
â”œâ”€â”€ bert_base/
â”‚   â”œâ”€â”€ naive/
â”‚   â”‚   â”œâ”€â”€ saliency_kde.png              [Label 0 vs 1 saliency]
â”‚   â”‚   â”œâ”€â”€ shap_kde.png                  [Label 0 vs 1 SHAP]
â”‚   â”‚   â”œâ”€â”€ statistics.json               [Numerical stats]
â”‚   â”‚   â””â”€â”€ conversations/
â”‚   â”‚       â”œâ”€â”€ MDRW1900000001.html      [Interactive viz]
â”‚   â”‚       â”œâ”€â”€ MDRW1900000002.html
â”‚   â”‚       â””â”€â”€ ... (up to 10 conversations)
â”‚   â””â”€â”€ trained/
â”‚       â””â”€â”€ [same structure]
â”‚
â”œâ”€â”€ distillbert_base/  [same structure]
â”œâ”€â”€ electra_base/      [same structure]
â”œâ”€â”€ roberta_base/      [same structure]
â”œâ”€â”€ roberta_large/     [same structure]
â”‚
â”œâ”€â”€ bert_base_naive_vs_trained.png         [2x2 comparison]
â”œâ”€â”€ distillbert_base_naive_vs_trained.png  [2x2 comparison]
â”œâ”€â”€ electra_base_naive_vs_trained.png      [2x2 comparison]
â”œâ”€â”€ roberta_base_naive_vs_trained.png      [2x2 comparison]
â”œâ”€â”€ roberta_large_naive_vs_trained.png     [2x2 comparison]
â””â”€â”€ summary_all_models.png                 [All models overview]

Total files generated: ~60-80 files (depends on conversations analyzed)

================================================================================
HOW TO RUN
================================================================================

Option 1 (Easiest):
   cd /home/minseok/forensic
   ./run_xai_analysis.sh

Option 2 (Manual):
   conda activate forensic
   python xai_analysis.py

Option 3 (Conda run):
   conda run -n forensic python xai_analysis.py

================================================================================
EXPECTED RUNTIME
================================================================================

Per Model (NAIVE + TRAINED):
   â€¢ SHAP computation:        ~10-15 minutes
   â€¢ Saliency computation:    ~15-20 minutes
   â€¢ Visualization generation: ~5 minutes
   â€¢ Total per model:         ~30-60 minutes

All 5 Models:
   â€¢ Estimated total time:    ~2.5-5 hours
   â€¢ GPU recommended for speed
   â€¢ CUDA detected: âœ… Available

Memory Requirements:
   â€¢ GPU RAM: 8-16 GB recommended
   â€¢ System RAM: 16 GB recommended
   â€¢ Disk space: ~500 MB for outputs

================================================================================
CUSTOMIZATION
================================================================================

Edit xai_analysis.py to customize:

Line 529: Number of conversations
   data = load_test_data(DATA_PATH, max_conversations=50)

Line 128: SHAP sample size
   shap_values = compute_shap(model, tokenizer, all_texts, device, max_samples=100)

Line 48: Output directory
   OUTPUT_DIR = '/home/minseok/forensic/xai_results'

Line 51: Input data path
   DATA_PATH = '/home/minseok/forensic/test_gpt.json'

Line 42-53: Model configurations
   MODEL_CONFIGS = { ... }

================================================================================
WHAT TO LOOK FOR IN RESULTS
================================================================================

âœ“ Good Model Behavior:
   â€¢ Higher saliency on drug terms for slang utterances
   â€¢ Clear separation in KDE plots between label 0 and 1
   â€¢ Trained model shows more focused attention than naive
   â€¢ Drug slang terms highlighted in red in HTML
   â€¢ Higher mean saliency for label 1 vs label 0

âœ— Poor Model Behavior:
   â€¢ Random/unfocused saliency distribution
   â€¢ No separation between label 0 and 1
   â€¢ No difference between naive and trained
   â€¢ Non-drug terms getting high attention
   â€¢ Similar mean values for both labels

================================================================================
KEY METRICS TO REPORT
================================================================================

From statistics.json:

1. label_1_saliency_mean - label_0_saliency_mean
   â†’ Larger difference = better discrimination

2. label_1_shap_mean / label_0_shap_mean
   â†’ Larger ratio = better slang detection

3. Compare naive vs trained for same metrics
   â†’ Improvement = effective training

4. Visual inspection of HTML files
   â†’ Verify drug terms are highlighted

================================================================================
REFERENCE IMPLEMENTATION
================================================================================

Saliency computation based on:
   /home/minseok/binshot_attk/saliency4.py

Key differences:
   â€¢ Adapted for sequence classification (not similarity)
   â€¢ Uses transformer embeddings (not custom BERT)
   â€¢ Simplified for binary classification
   â€¢ Added SHAP analysis
   â€¢ Enhanced visualizations

================================================================================
TROUBLESHOOTING
================================================================================

Issue: Out of GPU memory
Fix: Reduce max_conversations or max_samples

Issue: Too slow
Fix: Use fewer models, reduce sample sizes

Issue: Import errors
Fix: conda activate forensic && pip install -r requirements_xai.txt

Issue: Model checkpoint not found
Fix: Verify paths in MODEL_CONFIGS match your checkpoints

Issue: No output generated
Fix: Check xai_results/ directory permissions

================================================================================
NEXT STEPS
================================================================================

1. Run the analysis:
   ./run_xai_analysis.sh

2. While running:
   â€¢ Monitor progress in terminal
   â€¢ Check memory usage (nvidia-smi)
   â€¢ Estimated 2.5-5 hours total

3. After completion:
   â€¢ Open HTML files in browser
   â€¢ Review KDE plots
   â€¢ Compare naive_vs_trained plots
   â€¢ Read statistics.json files
   â€¢ Use for paper/presentation

4. For paper/analysis:
   â€¢ Include KDE plots showing separation
   â€¢ Show example HTML visualizations
   â€¢ Report statistics from JSON
   â€¢ Compare across models
   â€¢ Highlight trained vs naive improvements

================================================================================
SUPPORT
================================================================================

Documentation:
   â€¢ QUICKSTART_XAI.md - Quick start guide
   â€¢ XAI_README.md - Detailed documentation
   â€¢ This file - Quick reference

Code:
   â€¢ xai_analysis.py - Well-commented implementation
   â€¢ Inline documentation for all functions

Questions:
   â€¢ Check README files first
   â€¢ Review code comments
   â€¢ Test with small subset (10 conversations, 1 model)

================================================================================
READY TO RUN!
================================================================================

All files created âœ…
Dependencies installed âœ…
CUDA available âœ…
Test data verified âœ…
Models detected âœ…

Execute: ./run_xai_analysis.sh

Good luck with your research! ğŸš€

================================================================================
